{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3. SORU\n",
        "Bu soru icin 5-8 saatten fazlasina ihtiyac var, sadece computation/traininig bile daaha faazla surer!"
      ],
      "metadata": {
        "id": "Y0nLemWsuTGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting the Google Drive Connection"
      ],
      "metadata": {
        "id": "4T3LTnOquXX3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "0f5KpQDwKVgw",
        "outputId": "1f283a35-5408-41db-c7a8-b3536ab1cdde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We're running Colab\n",
            "Colab: mounting Google drive on  /content/gdrive\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "\n",
            "Colab: making sure  /content/gdrive/My Drive/stackoverflow  exists.\n",
            "\n",
            "Colab: Changing directory to  /content/gdrive/My Drive/stackoverflow\n",
            "/content/gdrive/My Drive/stackoverflow\n",
            "========================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/My Drive/stackoverflow'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# COLAB GOOGLE DRIVE CONNECTION/ MOUNT\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False\n",
        "\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")\n",
        "\n",
        "  # MOUNT\n",
        "if IN_COLAB:\n",
        "  # Mount the Google Drive at mount\n",
        "  mount='/content/gdrive'\n",
        "  print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "  drive.mount(mount)\n",
        "\n",
        "  # Switch to the directory on the Google Drive that you want to use\n",
        "  import os\n",
        "  drive_root = mount + \"/My Drive/stackoverflow\"\n",
        "  \n",
        "  # Create drive_root if it doesn't exist\n",
        "  create_drive_root = True\n",
        "  if create_drive_root:\n",
        "    print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "    os.makedirs(drive_root, exist_ok=True)\n",
        "  \n",
        "  # Change to the directory\n",
        "  print(\"\\nColab: Changing directory to \", drive_root)\n",
        "  %cd $drive_root\n",
        "print('='*40)\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary moduls\n"
      ],
      "metadata": {
        "id": "sC92Rkz-ugwI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Yyuafq5Khfw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh4OtBh_LIo5"
      },
      "source": [
        "## Load and View Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGD84L63LAyK",
        "outputId": "771912cb-f7bd-4312-eacb-c979005e2448"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32890, 10)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_set = pd.read_csv(\"stack.csv\")\n",
        "data_set.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWYCB-RfZDF1",
        "outputId": "d20a2eaa-7dbf-46b0-b59b-ec860e964f93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = data_set[0:1000]\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "lsVeGgp6ZZQ_",
        "outputId": "cfdab5b0-f39d-464c-b246-d7348884e414"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6c8a49b1-5070-4087-b677-1b184832b415\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tags</th>\n",
              "      <th>owner</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>score</th>\n",
              "      <th>last_activity_date</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>question_id</th>\n",
              "      <th>view_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1328</td>\n",
              "      <td>['python', 'pip', 'tox']</td>\n",
              "      <td>{'reputation': 38, 'user_id': 17981284, 'displ...</td>\n",
              "      <td>tox refuses to use deps setting in py38 and va...</td>\n",
              "      <td>I have a Django project that i'm trying to set...</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-04-05 03:47:16</td>\n",
              "      <td>2022-04-01 00:22:22</td>\n",
              "      <td>71700514</td>\n",
              "      <td>467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2385</td>\n",
              "      <td>['python', 'pip', 'easyocr']</td>\n",
              "      <td>{'reputation': 11, 'user_id': 18649779, 'displ...</td>\n",
              "      <td>easyocr installation error when install pillow</td>\n",
              "      <td>I'm trying to install the easyocr library, but...</td>\n",
              "      <td>-1</td>\n",
              "      <td>2022-04-03 14:42:33</td>\n",
              "      <td>2022-04-01 00:27:03</td>\n",
              "      <td>71700531</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2175</td>\n",
              "      <td>['python', 'reduce', 'numba', 'jit', 'jax']</td>\n",
              "      <td>{'reputation': 79, 'user_id': 18649992, 'displ...</td>\n",
              "      <td>JAX(XLA) vs Numba(LLVM) Reduction</td>\n",
              "      <td>Is it possible to make CPU only reductions wit...</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-04-03 23:01:43</td>\n",
              "      <td>2022-04-01 02:15:55</td>\n",
              "      <td>71701041</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c8a49b1-5070-4087-b677-1b184832b415')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c8a49b1-5070-4087-b677-1b184832b415 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c8a49b1-5070-4087-b677-1b184832b415');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0                                         tags  \\\n",
              "0        1328                     ['python', 'pip', 'tox']   \n",
              "1        2385                 ['python', 'pip', 'easyocr']   \n",
              "2        2175  ['python', 'reduce', 'numba', 'jit', 'jax']   \n",
              "\n",
              "                                               owner  \\\n",
              "0  {'reputation': 38, 'user_id': 17981284, 'displ...   \n",
              "1  {'reputation': 11, 'user_id': 18649779, 'displ...   \n",
              "2  {'reputation': 79, 'user_id': 18649992, 'displ...   \n",
              "\n",
              "                                               title  \\\n",
              "0  tox refuses to use deps setting in py38 and va...   \n",
              "1     easyocr installation error when install pillow   \n",
              "2                  JAX(XLA) vs Numba(LLVM) Reduction   \n",
              "\n",
              "                                                body  score  \\\n",
              "0  I have a Django project that i'm trying to set...      0   \n",
              "1  I'm trying to install the easyocr library, but...     -1   \n",
              "2  Is it possible to make CPU only reductions wit...      2   \n",
              "\n",
              "    last_activity_date        creation_date  question_id  view_count  \n",
              "0  2022-04-05 03:47:16  2022-04-01 00:22:22     71700514         467  \n",
              "1  2022-04-03 14:42:33  2022-04-01 00:27:03     71700531         132  \n",
              "2  2022-04-03 23:01:43  2022-04-01 02:15:55     71701041         713  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing"
      ],
      "metadata": {
        "id": "1DNBFa5BuxzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLlhAqtQLAv0"
      },
      "outputs": [],
      "source": [
        "for i in range(0, (len(df) ) ):\n",
        "  #tags = df['tags'].values[i]\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\"\\n\", \"\\n_\\n \")\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\"\\n_\", df['tags'].values[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aahbkY8vLAtO"
      },
      "outputs": [],
      "source": [
        "for i in range(0, (len(df) ) ):\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\"'\",\"\")\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\"[\", ' ')\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\"]\", ' ')\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\"(\", ' ')\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\")\", ' ')\n",
        "  df['body'].values[i] = df['body'].values[i].replace(\",\", ' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a CORPUS and TOKENIZE:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "s4PIXVbZvCNK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3ufO4N_L4BF"
      },
      "outputs": [],
      "source": [
        "def create_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XixHE5UMLAoi",
        "outputId": "490df258-a71e-475c-9e53-1485b847e485"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n"
          ]
        }
      ],
      "source": [
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_corpus(df, 'body')\n",
        "\n",
        "# Tokenize the corpus\n",
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4Z2NB1cLAmK"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "#max_sequence_len = max([len(seq) for seq in sequences])\n",
        "maxmax_sequence_len=100\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=100, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODEL AND APPROACH\n",
        "\n",
        "\n",
        "> I've dealt this task as ***to create a model which produces new words/sentences.*** like a word generating NLP model, the trained model can guess possible tags from the corpus (generated by body columns' of the dataset).\n",
        "\n",
        "> For every sample in the dataset, the tags are added in the end of every line (before \"\\n\" symbol). Then, every line is treated as a squence and expect the model to learn suitable tags after a consesequitive word sequence.\n",
        "\n",
        "> But, this process ***requires a great many of GPU power and RAM***. Even though I use a Colab PRO account, I couldnâ€™t achieve to deal all the dataset and limit number of the of the words to 100. \n",
        "\n",
        "> These limitations made training a little bit long (several times, I dropped and session was stopped, etc.)\n",
        "\n",
        "> After several trials; I trained ***the model and tried it with both real data and several artificial statements***. The results are ***satisfactory enough.***\n",
        "\n",
        "***REMEMBER:*** the model produces ***a probability distrubution function (using softmax) ***for possible outcomes. I only print out 5 top probable candidate tags."
      ],
      "metadata": {
        "id": "ICWWh2-ty6i8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL and APPROACH"
      ],
      "metadata": {
        "id": "0H7x8hXSy2DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCbnRZ97vrYV",
        "outputId": "57d07ee6-0636-492a-8c19-fb4db381761d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.9810 - accuracy: 0.2986WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 43s 11ms/step - loss: 2.9810 - accuracy: 0.2986\n",
            "Epoch 2/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.6096 - accuracy: 0.3523WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.6096 - accuracy: 0.3523\n",
            "Epoch 3/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.5401 - accuracy: 0.3632WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.5401 - accuracy: 0.3632\n",
            "Epoch 4/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.5031 - accuracy: 0.3682WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.5031 - accuracy: 0.3682\n",
            "Epoch 5/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.4798 - accuracy: 0.3718WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4799 - accuracy: 0.3718\n",
            "Epoch 6/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.4638 - accuracy: 0.3730WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.4640 - accuracy: 0.3729\n",
            "Epoch 7/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.4532 - accuracy: 0.3744WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4531 - accuracy: 0.3745\n",
            "Epoch 8/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.4445 - accuracy: 0.3760WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4446 - accuracy: 0.3760\n",
            "Epoch 9/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.4374 - accuracy: 0.3770WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4374 - accuracy: 0.3770\n",
            "Epoch 10/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.4313 - accuracy: 0.3780WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4313 - accuracy: 0.3780\n",
            "Epoch 11/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.4263 - accuracy: 0.3781WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4263 - accuracy: 0.3781\n",
            "Epoch 12/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.4210 - accuracy: 0.3786WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4210 - accuracy: 0.3786\n",
            "Epoch 13/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.4173 - accuracy: 0.3802WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4172 - accuracy: 0.3802\n",
            "Epoch 14/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.4132 - accuracy: 0.3805WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4131 - accuracy: 0.3805\n",
            "Epoch 15/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.4099 - accuracy: 0.3821WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4100 - accuracy: 0.3821\n",
            "Epoch 16/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.4066 - accuracy: 0.3818WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4066 - accuracy: 0.3818\n",
            "Epoch 17/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.4032 - accuracy: 0.3815WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4032 - accuracy: 0.3815\n",
            "Epoch 18/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.4007 - accuracy: 0.3822WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.4007 - accuracy: 0.3823\n",
            "Epoch 19/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3977 - accuracy: 0.3835WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3977 - accuracy: 0.3835\n",
            "Epoch 20/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3948 - accuracy: 0.3835WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3949 - accuracy: 0.3835\n",
            "Epoch 21/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3926 - accuracy: 0.3837WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3926 - accuracy: 0.3837\n",
            "Epoch 22/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3899 - accuracy: 0.3840WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3900 - accuracy: 0.3840\n",
            "Epoch 23/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3876 - accuracy: 0.3851WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3875 - accuracy: 0.3850\n",
            "Epoch 24/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3857 - accuracy: 0.3852WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3857 - accuracy: 0.3852\n",
            "Epoch 25/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3835 - accuracy: 0.3856WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3836 - accuracy: 0.3855\n",
            "Epoch 26/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3821 - accuracy: 0.3861WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3821 - accuracy: 0.3861\n",
            "Epoch 27/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3798 - accuracy: 0.3860WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3798 - accuracy: 0.3860\n",
            "Epoch 28/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3778 - accuracy: 0.3868WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3778 - accuracy: 0.3868\n",
            "Epoch 29/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3764 - accuracy: 0.3870WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3763 - accuracy: 0.3870\n",
            "Epoch 30/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3747 - accuracy: 0.3869WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3747 - accuracy: 0.3869\n",
            "Epoch 31/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3737 - accuracy: 0.3871WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3736 - accuracy: 0.3871\n",
            "Epoch 32/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3715 - accuracy: 0.3876WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3716 - accuracy: 0.3876\n",
            "Epoch 33/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3710 - accuracy: 0.3878WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3708 - accuracy: 0.3878\n",
            "Epoch 34/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3690 - accuracy: 0.3883WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3689 - accuracy: 0.3883\n",
            "Epoch 35/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3676 - accuracy: 0.3889WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3674 - accuracy: 0.3890\n",
            "Epoch 36/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3662 - accuracy: 0.3885WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3662 - accuracy: 0.3885\n",
            "Epoch 37/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3654 - accuracy: 0.3890WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3652 - accuracy: 0.3890\n",
            "Epoch 38/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3641 - accuracy: 0.3893WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3641 - accuracy: 0.3893\n",
            "Epoch 39/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3630 - accuracy: 0.3898WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3630 - accuracy: 0.3897\n",
            "Epoch 40/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3618 - accuracy: 0.3898WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3618 - accuracy: 0.3898\n",
            "Epoch 41/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3600 - accuracy: 0.3896WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3602 - accuracy: 0.3896\n",
            "Epoch 42/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3598 - accuracy: 0.3903WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3599 - accuracy: 0.3902\n",
            "Epoch 43/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3582 - accuracy: 0.3902WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3582 - accuracy: 0.3902\n",
            "Epoch 44/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3579 - accuracy: 0.3902WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3578 - accuracy: 0.3901\n",
            "Epoch 45/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3569 - accuracy: 0.3898WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3568 - accuracy: 0.3899\n",
            "Epoch 46/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3560 - accuracy: 0.3908WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 39s 11ms/step - loss: 2.3560 - accuracy: 0.3908\n",
            "Epoch 47/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3544 - accuracy: 0.3910WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3544 - accuracy: 0.3910\n",
            "Epoch 48/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3544 - accuracy: 0.3903WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3544 - accuracy: 0.3902\n",
            "Epoch 49/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3538 - accuracy: 0.3913WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3538 - accuracy: 0.3913\n",
            "Epoch 50/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3524 - accuracy: 0.3911WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3524 - accuracy: 0.3911\n",
            "Epoch 51/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3521 - accuracy: 0.3910WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3521 - accuracy: 0.3910\n",
            "Epoch 52/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3516 - accuracy: 0.3910WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3516 - accuracy: 0.3910\n",
            "Epoch 53/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3507 - accuracy: 0.3915WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3507 - accuracy: 0.3915\n",
            "Epoch 54/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3496 - accuracy: 0.3927WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3496 - accuracy: 0.3926\n",
            "Epoch 55/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3494 - accuracy: 0.3915WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3492 - accuracy: 0.3916\n",
            "Epoch 56/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3486 - accuracy: 0.3921WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3485 - accuracy: 0.3921\n",
            "Epoch 57/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3478 - accuracy: 0.3919WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3478 - accuracy: 0.3919\n",
            "Epoch 58/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3475 - accuracy: 0.3917WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3473 - accuracy: 0.3917\n",
            "Epoch 59/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3468 - accuracy: 0.3919WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3468 - accuracy: 0.3920\n",
            "Epoch 60/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3459 - accuracy: 0.3935WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3460 - accuracy: 0.3934\n",
            "Epoch 61/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3454 - accuracy: 0.3925WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3455 - accuracy: 0.3925\n",
            "Epoch 62/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3447 - accuracy: 0.3928WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3447 - accuracy: 0.3928\n",
            "Epoch 63/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3447 - accuracy: 0.3930WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3448 - accuracy: 0.3930\n",
            "Epoch 64/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3436 - accuracy: 0.3938WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3437 - accuracy: 0.3938\n",
            "Epoch 65/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3435 - accuracy: 0.3929WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3434 - accuracy: 0.3930\n",
            "Epoch 66/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3434 - accuracy: 0.3929WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3434 - accuracy: 0.3929\n",
            "Epoch 67/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3423 - accuracy: 0.3929WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3423 - accuracy: 0.3929\n",
            "Epoch 68/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3423 - accuracy: 0.3931WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3421 - accuracy: 0.3931\n",
            "Epoch 69/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3418 - accuracy: 0.3934WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3416 - accuracy: 0.3934\n",
            "Epoch 70/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3410 - accuracy: 0.3940WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3410 - accuracy: 0.3940\n",
            "Epoch 71/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3407 - accuracy: 0.3930WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3406 - accuracy: 0.3930\n",
            "Epoch 72/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3402 - accuracy: 0.3931WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3402 - accuracy: 0.3931\n",
            "Epoch 73/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3397 - accuracy: 0.3936WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3397 - accuracy: 0.3936\n",
            "Epoch 74/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3390 - accuracy: 0.3946WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3390 - accuracy: 0.3946\n",
            "Epoch 75/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3388 - accuracy: 0.3943WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3389 - accuracy: 0.3943\n",
            "Epoch 76/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3382 - accuracy: 0.3939WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3382 - accuracy: 0.3939\n",
            "Epoch 77/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3391 - accuracy: 0.3944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3389 - accuracy: 0.3945\n",
            "Epoch 78/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3376 - accuracy: 0.3943WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3375 - accuracy: 0.3943\n",
            "Epoch 79/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3368 - accuracy: 0.3934WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3368 - accuracy: 0.3935\n",
            "Epoch 80/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3369 - accuracy: 0.3939WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3369 - accuracy: 0.3939\n",
            "Epoch 81/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3362 - accuracy: 0.3947WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3363 - accuracy: 0.3947\n",
            "Epoch 82/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3361 - accuracy: 0.3940WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3361 - accuracy: 0.3940\n",
            "Epoch 83/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3356 - accuracy: 0.3945WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3356 - accuracy: 0.3945\n",
            "Epoch 84/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3352 - accuracy: 0.3939WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3352 - accuracy: 0.3939\n",
            "Epoch 85/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3349 - accuracy: 0.3942WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3348 - accuracy: 0.3942\n",
            "Epoch 86/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3343 - accuracy: 0.3952WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3343 - accuracy: 0.3952\n",
            "Epoch 87/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3342 - accuracy: 0.3948WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3343 - accuracy: 0.3948\n",
            "Epoch 88/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3338 - accuracy: 0.3948WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3338 - accuracy: 0.3949\n",
            "Epoch 89/100\n",
            "3466/3470 [============================>.] - ETA: 0s - loss: 2.3334 - accuracy: 0.3949WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3334 - accuracy: 0.3949\n",
            "Epoch 90/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3335 - accuracy: 0.3952WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3334 - accuracy: 0.3953\n",
            "Epoch 91/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3323 - accuracy: 0.3961WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3324 - accuracy: 0.3961\n",
            "Epoch 92/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3321 - accuracy: 0.3951WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3321 - accuracy: 0.3951\n",
            "Epoch 93/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3320 - accuracy: 0.3956WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3318 - accuracy: 0.3956\n",
            "Epoch 94/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3317 - accuracy: 0.3955WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3316 - accuracy: 0.3955\n",
            "Epoch 95/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3314 - accuracy: 0.3957WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3314 - accuracy: 0.3957\n",
            "Epoch 96/100\n",
            "3470/3470 [==============================] - ETA: 0s - loss: 2.3309 - accuracy: 0.3959WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3309 - accuracy: 0.3959\n",
            "Epoch 97/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3308 - accuracy: 0.3956WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3309 - accuracy: 0.3956\n",
            "Epoch 98/100\n",
            "3469/3470 [============================>.] - ETA: 0s - loss: 2.3302 - accuracy: 0.3958WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3302 - accuracy: 0.3959\n",
            "Epoch 99/100\n",
            "3468/3470 [============================>.] - ETA: 0s - loss: 2.3300 - accuracy: 0.3962WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 12ms/step - loss: 2.3300 - accuracy: 0.3961\n",
            "Epoch 100/100\n",
            "3467/3470 [============================>.] - ETA: 0s - loss: 2.3300 - accuracy: 0.3964WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "3470/3470 [==============================] - 40s 11ms/step - loss: 2.3302 - accuracy: 0.3964\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=100-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"my_checkpoint_case3.h5\", save_best_only=True)\n",
        "\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1, callbacks= model_checkpoint )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "c3uad40hMjZV",
        "outputId": "c64905fe-63ed-4061-8959-a8aefa4d013f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-fYMHh95dcW",
        "outputId": "f8dccc62-5b45-4263-8880-e58de96023e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm creating a dictionary from json data. I have a value 'actions' which is not on all the descriptions but I would like to add it to the ones that have it. How would I do it?\n",
            "I tried to do it that way item['actions'] if item['actions'] else None but I'm still getting a keyerror with it.\n",
            " desc = {item['classid']: \n",
            "    [\n",
            "        item['name'],\n",
            "        item['market_hash_name'],\n",
            "        item['icon_url'],\n",
            "        item['tradable'],\n",
            "        item['actions'] if item['actions'] else None\n",
            "    ] for item in inventory['descriptions']}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print( data_set['body'].values[2023] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_InMn12Ehw0",
        "outputId": "37299d70-e50b-4f2d-d878-b5f98fef9123"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['python', 'list']\n"
          ]
        }
      ],
      "source": [
        "print( data_set['tags'].values[2023] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQiGMBQNMjVK",
        "outputId": "471e5559-4074-421e-bb56-ce2ba9065adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm creating a dictionary from json data. python dictionary output\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"I'm creating a dictionary from json data.\"\n",
        "next_words = 3\n",
        "max_sequence_len=15\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRODUCED TAGS FOR A PORTION OF THE REAL STATEMENT: [python], [dictionary], [output]\n",
        "AND REAL TAGS ARE: [python], [list]"
      ],
      "metadata": {
        "id": "pNUy69zKz4Zy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5J8J7DjMjRB",
        "outputId": "9d0f1e9c-1533-4270-ee10-0d73f37688cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "how to merge 2 columns of a df python pandas dataframe numpy pythonrequests\n"
          ]
        }
      ],
      "source": [
        "#an aarbitrary text is given\n",
        "# the model produces palusible tags\n",
        "# remember the corpus is highly dominated via tags.\n",
        "\n",
        "seed_text = \"how to merge 2 columns of a df\"\n",
        "next_words = 5\n",
        "max_sequence_len=100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRODUCED TAGS FOR A SYNTETIC STATEMENT: [python], [pandas], [dataframe], [numpy], [pythonrequets]"
      ],
      "metadata": {
        "id": "rkKjxbipzgLl"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "STM_Case_3.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}